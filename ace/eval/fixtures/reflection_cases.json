{
  "version": "1.0",
  "description": "Test fixtures for reflection quality evaluation. Each case contains task data and expected reflection characteristics.",
  "cases": [
    {
      "id": "refl-001",
      "name": "API timeout failure - retry logic needed",
      "task_data": {
        "query": "Add retry logic to API calls",
        "retrieved_bullet_ids": ["strat-00045", "code-00089"],
        "code_diff": "--- a/api_client.py\n+++ b/api_client.py\n@@ -10,7 +10,7 @@\n def fetch_data(url):\n-    response = requests.get(url)\n+    response = requests.get(url, timeout=30)\n     return response.json()",
        "test_output": "FAILED tests/test_api.py::test_api_timeout - TimeoutError: Request timed out after 30s",
        "logs": "ERROR: Connection failed after timeout\nERROR: No retry mechanism configured",
        "env": {
          "repo": "ace",
          "stack": "python",
          "topic": "api"
        }
      },
      "expected": {
        "error_identification": true,
        "root_cause_analysis": true,
        "correct_approach": true,
        "key_insight": true,
        "min_candidate_bullets": 1,
        "should_tag_bullets": false,
        "candidate_sections": ["strategies", "code_snippets"],
        "candidate_tags": ["topic:retry", "topic:api", "stack:python"]
      }
    },
    {
      "id": "refl-002",
      "name": "Database connection pool exhaustion",
      "task_data": {
        "query": "Fix database connection pool errors",
        "retrieved_bullet_ids": ["strat-00091", "trbl-00023"],
        "code_diff": "--- a/db.py\n+++ b/db.py\n@@ -5,7 +5,7 @@\n-engine = create_engine(DATABASE_URL)\n+engine = create_engine(DATABASE_URL, pool_size=10, max_overflow=20)",
        "test_output": "FAILED tests/test_db.py::test_concurrent_queries - sqlalchemy.exc.TimeoutError: QueuePool limit exceeded",
        "logs": "WARNING: Connection pool size exceeded\nERROR: Cannot acquire connection from pool",
        "env": {
          "repo": "ace",
          "stack": "python",
          "topic": "database",
          "db": "postgresql"
        }
      },
      "expected": {
        "error_identification": true,
        "root_cause_analysis": true,
        "correct_approach": true,
        "min_candidate_bullets": 1,
        "should_tag_helpful": ["strat-00091"],
        "candidate_sections": ["strategies", "troubleshooting"],
        "candidate_tags": ["db:postgresql", "topic:connection-pool", "stack:python"]
      }
    },
    {
      "id": "refl-003",
      "name": "Successful implementation - tag helpful bullets",
      "task_data": {
        "query": "Implement JSON schema validation",
        "retrieved_bullet_ids": ["tmpl-00045", "code-00112"],
        "code_diff": "--- a/validator.py\n+++ b/validator.py\n@@ -1,0 +2,10 @@\n+import jsonschema\n+\n+def validate_reflection(data):\n+    schema = {...}\n+    jsonschema.validate(data, schema)\n+    return True",
        "test_output": "PASSED tests/test_validator.py::test_schema_validation - 5/5 tests passed",
        "logs": "INFO: Schema validation successful\nINFO: All test cases passed",
        "env": {
          "repo": "ace",
          "stack": "python",
          "topic": "validation"
        }
      },
      "expected": {
        "error_identification": false,
        "key_insight": true,
        "min_candidate_bullets": 0,
        "should_tag_helpful": ["tmpl-00045", "code-00112"],
        "candidate_sections": [],
        "candidate_tags": []
      }
    },
    {
      "id": "refl-004",
      "name": "Misleading bullet - mark harmful",
      "task_data": {
        "query": "Fix memory leak in event loop",
        "retrieved_bullet_ids": ["strat-00067", "trbl-00088"],
        "code_diff": "--- a/event_loop.py\n+++ b/event_loop.py\n@@ -15,7 +15,7 @@\n-    # Applied strat-00067 suggestion to increase buffer\n-    buffer_size = 10000\n+    # Properly close connections instead\n+    connection.close()",
        "test_output": "PASSED tests/test_memory.py::test_no_leak - Memory usage stable after 1000 iterations",
        "logs": "INFO: Bullet strat-00067 suggested wrong approach (increase buffer)\nINFO: Root cause was unclosed connections",
        "env": {
          "repo": "ace",
          "stack": "python",
          "topic": "memory"
        }
      },
      "expected": {
        "error_identification": false,
        "root_cause_analysis": true,
        "key_insight": true,
        "min_candidate_bullets": 1,
        "should_tag_harmful": ["strat-00067"],
        "should_tag_helpful": [],
        "candidate_sections": ["troubleshooting", "strategies"],
        "candidate_tags": ["topic:memory", "topic:event-loop", "stack:python"]
      }
    },
    {
      "id": "refl-005",
      "name": "No bullets retrieved - cold start scenario",
      "task_data": {
        "query": "Implement WebSocket reconnection with exponential backoff",
        "retrieved_bullet_ids": [],
        "code_diff": "--- a/websocket_client.py\n+++ b/websocket_client.py\n@@ -0,0 +20 @@\n+class ReconnectingWebSocket:\n+    def __init__(self):\n+        self.backoff = 1\n+        self.max_backoff = 60\n+    \n+    async def connect_with_retry(self):\n+        while True:\n+            try:\n+                await self.connect()\n+                self.backoff = 1\n+                break\n+            except ConnectionError:\n+                await asyncio.sleep(self.backoff)\n+                self.backoff = min(self.backoff * 2, self.max_backoff)",
        "test_output": "PASSED tests/test_websocket.py::test_reconnect - Reconnection successful after 3 attempts",
        "logs": "INFO: Implemented exponential backoff successfully",
        "env": {
          "repo": "ace",
          "stack": "python",
          "topic": "websocket"
        }
      },
      "expected": {
        "error_identification": false,
        "key_insight": true,
        "correct_approach": true,
        "min_candidate_bullets": 2,
        "should_tag_bullets": false,
        "candidate_sections": ["strategies", "code_snippets"],
        "candidate_tags": ["topic:websocket", "topic:retry", "topic:backoff", "stack:python"]
      }
    },
    {
      "id": "refl-006",
      "name": "Parser error - JSON strictness issue",
      "task_data": {
        "query": "Debug reflection parser failures",
        "retrieved_bullet_ids": ["trbl-00056"],
        "code_diff": "--- a/reflector/parser.py\n+++ b/reflector/parser.py\n@@ -10,7 +10,12 @@\n def parse_reflection(text):\n-    return json.loads(text)\n+    # Remove markdown code fences if present\n+    if text.strip().startswith('```'):\n+        lines = text.strip().split('\\n')\n+        text = '\\n'.join(lines[1:-1])\n+    return json.loads(text)",
        "test_output": "FAILED tests/test_parser.py::test_parse_reflection - JSONDecodeError: Expecting value",
        "logs": "ERROR: LLM output contained markdown fencing: ```json\\n{...}\\n```\nERROR: Parser failed to extract valid JSON",
        "env": {
          "repo": "ace",
          "stack": "python",
          "topic": "parsing"
        }
      },
      "expected": {
        "error_identification": true,
        "root_cause_analysis": true,
        "correct_approach": true,
        "key_insight": true,
        "min_candidate_bullets": 1,
        "should_tag_helpful": ["trbl-00056"],
        "candidate_sections": ["troubleshooting", "code_snippets"],
        "candidate_tags": ["topic:parsing", "topic:json", "topic:robustness"]
      }
    },
    {
      "id": "refl-007",
      "name": "Deduplication logic - refine phase",
      "task_data": {
        "query": "Implement duplicate bullet detection",
        "retrieved_bullet_ids": ["strat-00102", "code-00145"],
        "code_diff": "--- a/refine/dedup.py\n+++ b/refine/dedup.py\n@@ -0,0 +30 @@\n+def find_near_duplicates(bullets, threshold=0.90):\n+    for i, b1 in enumerate(bullets):\n+        for b2 in bullets[i+1:]:\n+            cosine_sim = compute_embedding_similarity(b1, b2)\n+            jaccard_sim = compute_minhash_jaccard(b1, b2)\n+            if cosine_sim > threshold or jaccard_sim > 0.85:\n+                yield (b1, b2, max(cosine_sim, jaccard_sim))",
        "test_output": "PASSED tests/test_dedup.py::test_near_duplicates - Found 12 duplicate pairs in test set",
        "logs": "INFO: Using hybrid similarity: embedding cosine + minhash Jaccard\nINFO: Threshold: 0.90 for embeddings, 0.85 for Jaccard",
        "env": {
          "repo": "ace",
          "stack": "python",
          "topic": "refine"
        }
      },
      "expected": {
        "error_identification": false,
        "key_insight": true,
        "correct_approach": true,
        "min_candidate_bullets": 1,
        "should_tag_helpful": ["strat-00102"],
        "candidate_sections": ["strategies", "code_snippets"],
        "candidate_tags": ["topic:refine", "topic:dedup", "stack:python"]
      }
    },
    {
      "id": "refl-008",
      "name": "Migration scenario - breaking changes",
      "task_data": {
        "query": "Migrate from SQLAlchemy 1.4 to 2.0",
        "retrieved_bullet_ids": [],
        "code_diff": "--- a/models.py\n+++ b/models.py\n@@ -5,7 +5,7 @@\n-from sqlalchemy.orm import Query\n+from sqlalchemy import select\n \n def get_bullets(session):\n-    return session.query(Bullet).filter(Bullet.helpful > 0).all()\n+    stmt = select(Bullet).where(Bullet.helpful > 0)\n+    return session.execute(stmt).scalars().all()",
        "test_output": "FAILED tests/test_models.py::test_get_bullets - AttributeError: 'Query' object has no attribute 'scalars'",
        "logs": "ERROR: SQLAlchemy 2.0 removed legacy Query API\nERROR: Must use select() instead of session.query()",
        "env": {
          "repo": "ace",
          "stack": "python",
          "topic": "migration",
          "db": "sqlalchemy"
        }
      },
      "expected": {
        "error_identification": true,
        "root_cause_analysis": true,
        "correct_approach": true,
        "key_insight": true,
        "min_candidate_bullets": 2,
        "should_tag_bullets": false,
        "candidate_sections": ["troubleshooting", "code_snippets"],
        "candidate_tags": ["topic:migration", "db:sqlalchemy", "stack:python"]
      }
    },
    {
      "id": "refl-009",
      "name": "Security issue - secret exposure",
      "task_data": {
        "query": "Fix API key exposure in logs",
        "retrieved_bullet_ids": ["strat-00078"],
        "code_diff": "--- a/logger.py\n+++ b/logger.py\n@@ -15,7 +15,10 @@\n def log_request(url, headers):\n-    logger.info(f\"Request to {url} with headers: {headers}\")\n+    safe_headers = {k: v if k != 'Authorization' else '[REDACTED]' \n+                    for k, v in headers.items()}\n+    logger.info(f\"Request to {url} with headers: {safe_headers}\")",
        "test_output": "PASSED tests/test_logger.py::test_no_secrets_in_logs - No API keys found in log output",
        "logs": "INFO: Redacting Authorization header from logs\nINFO: Security check passed",
        "env": {
          "repo": "ace",
          "stack": "python",
          "topic": "security"
        }
      },
      "expected": {
        "error_identification": false,
        "key_insight": true,
        "correct_approach": true,
        "min_candidate_bullets": 1,
        "should_tag_helpful": ["strat-00078"],
        "candidate_sections": ["strategies", "code_snippets"],
        "candidate_tags": ["topic:security", "topic:logging", "stack:python"]
      }
    },
    {
      "id": "refl-010",
      "name": "Complex multi-step fix with multiple insights",
      "task_data": {
        "query": "Fix race condition in concurrent bullet updates",
        "retrieved_bullet_ids": ["strat-00091", "trbl-00034"],
        "code_diff": "--- a/store.py\n+++ b/store.py\n@@ -25,10 +25,15 @@\n def update_bullet_counters(bullet_id, helpful=0, harmful=0):\n-    bullet = session.query(Bullet).get(bullet_id)\n-    bullet.helpful += helpful\n-    bullet.harmful += harmful\n-    session.commit()\n+    # Use database-level atomic increment to prevent race conditions\n+    stmt = (\n+        update(Bullet)\n+        .where(Bullet.id == bullet_id)\n+        .values(\n+            helpful=Bullet.helpful + helpful,\n+            harmful=Bullet.harmful + harmful\n+        )\n+    )\n+    session.execute(stmt)\n+    session.commit()",
        "test_output": "PASSED tests/test_concurrent.py::test_concurrent_updates - All 100 concurrent updates applied correctly\nPREVIOUSLY FAILED: Lost updates due to read-modify-write race",
        "logs": "INFO: Replaced read-modify-write pattern with atomic UPDATE\nINFO: Database handles concurrency via row-level locking\nINFO: Previous approach had race window between read and write",
        "env": {
          "repo": "ace",
          "stack": "python",
          "topic": "concurrency",
          "db": "postgresql"
        }
      },
      "expected": {
        "error_identification": true,
        "root_cause_analysis": true,
        "correct_approach": true,
        "key_insight": true,
        "min_candidate_bullets": 2,
        "should_tag_helpful": ["strat-00091"],
        "should_tag_harmful": [],
        "candidate_sections": ["strategies", "troubleshooting", "code_snippets"],
        "candidate_tags": ["topic:concurrency", "topic:race-condition", "db:postgresql", "stack:python"]
      }
    }
  ]
}
